# Anywhere {branch} is used, the branch name will be substituted.
# These comments will also be removed.
defaults:
  numbered: False
  maxdepth: 6
root: index
subtrees:
- entries:
  - file: what-is-rocm.rst
  - file: about/release-notes.md
    title: Release notes
  - file: compatibility/compatibility-matrix.rst
    title: Compatibility matrix
    entries:
    - url: https://rocm.docs.amd.com/projects/install-on-linux/en/${branch}/reference/system-requirements.html
      title: Linux system requirements
    - url: https://rocm.docs.amd.com/projects/install-on-windows/en/${branch}/reference/system-requirements.html
      title: Windows system requirements

- caption: Install
  entries:
  - url: https://rocm.docs.amd.com/projects/install-on-linux/en/${branch}/
    title: ROCm on Linux
  - url: https://rocm.docs.amd.com/projects/install-on-windows/en/${branch}/
    title: HIP SDK on Windows
  - url: https://rocm.docs.amd.com/projects/radeon/en/latest/index.html
    title: ROCm on Radeon GPUs
  - file: how-to/deep-learning-rocm.md
    title: Deep learning frameworks
  - file: how-to/build-rocm.rst
    title: Build ROCm from source

- caption: How to
  entries:
  - file: how-to/rocm-for-ai/index.rst
    title: Use ROCm for AI
    subtrees:
    - entries:
      - file: how-to/rocm-for-ai/training/index.rst
        title: Training
        subtrees:
        - entries:
          - file: how-to/rocm-for-ai/training/train-a-model.rst
            title: Train a model
          - file: how-to/rocm-for-ai/training/scale-model-training.rst
            title: Scale model training
      
      - file: how-to/rocm-for-ai/fine-tuning/index.rst
        title: Fine-tuning LLMs
        subtrees:
        - entries:
          - file: how-to/rocm-for-ai/fine-tuning/overview.rst
            title: Conceptual overview
          - file: how-to/rocm-for-ai/fine-tuning/fine-tuning-and-inference.rst
            title: Fine-tuning
            subtrees:
            - entries:
              - file: how-to/rocm-for-ai/fine-tuning/single-gpu-fine-tuning-and-inference.rst
                title: Use a single accelerator
              - file: how-to/rocm-for-ai/fine-tuning/multi-gpu-fine-tuning-and-inference.rst
                title: Use multiple accelerators

      - file: how-to/rocm-for-ai/inference/index.rst
        title: Inference
        subtrees:
        - entries:
          - file: how-to/rocm-for-ai/inference/install.rst
            title: Installation
          - file: how-to/rocm-for-ai/inference/hugging-face-models.rst
            title: Run models from Hugging Face
          - file: how-to/rocm-for-ai/inference/llm-inference-frameworks.rst
            title: LLM inference frameworks
          - file: how-to/rocm-for-ai/inference/vllm-benchmark.rst
            title: Performance validation
          - file: how-to/rocm-for-ai/inference/deploy-your-model.rst
            title: Deploy your model

      - file: how-to/rocm-for-ai/inference-optimization/index.rst
        title: Inference optimization
        subtrees:
        - entries:
          - file: how-to/rocm-for-ai/inference-optimization/model-quantization.rst
          - file: how-to/rocm-for-ai/inference-optimization/model-acceleration-libraries.rst
          - file: how-to/rocm-for-ai/inference-optimization/optimizing-with-composable-kernel.md
            title: Optimize with Composable Kernel
          - file: how-to/rocm-for-ai/inference-optimization/optimizing-triton-kernel.rst
            title: Optimize Triton kernels
          - file: how-to/rocm-for-ai/inference-optimization/profiling-and-debugging.rst
            title: Profile and debug
          - file: how-to/rocm-for-ai/inference-optimization/workload.rst
            title: Workload tuning
  
  - file: how-to/rocm-for-hpc/index.rst
    title: Use ROCm for HPC
  - file: how-to/system-optimization/index.rst
    title: System optimization
    subtrees:
    - entries:
      - file: how-to/system-optimization/mi300x.rst
        title: AMD Instinct MI300X
      - file: how-to/system-optimization/mi300a.rst
        title: AMD Instinct MI300A
      - file: how-to/system-optimization/mi200.md
        title: AMD Instinct MI200
      - file: how-to/system-optimization/mi100.md
        title: AMD Instinct MI100
      - file: how-to/system-optimization/w6000-v620.md
        title: AMD RDNA 2
  - file: how-to/tuning-guides/mi300x/index.rst
    title: AMD MI300X performance validation and tuning
  - file: how-to/system-debugging.md
  - file: conceptual/compiler-topics.md
    title: Use advanced compiler features
    subtrees:
    - entries:
      - url: https://rocm.docs.amd.com/projects/llvm-project/en/latest/index.html
        title: ROCm compiler infrastructure
      - url: https://rocm.docs.amd.com/projects/llvm-project/en/latest/conceptual/using-gpu-sanitizer.html
        title: Use AddressSanitizer
      - url: https://rocm.docs.amd.com/projects/llvm-project/en/latest/conceptual/openmp.html
        title: OpenMP support
  - file: how-to/setting-cus
    title: Set the number of CUs
  - file: how-to/Bar-Memory.rst
    title: Troubleshoot BAR access limitation  
  - url: https://github.com/amd/rocm-examples
    title: ROCm examples

- caption: Conceptual
  entries:
  - file: conceptual/gpu-arch.md
    title: GPU architecture overview
    subtrees:
    - entries:
      - file: conceptual/gpu-arch/mi300.md
        title: MI300 microarchitecture
        subtrees:
        - entries:
          - url: https://www.amd.com/content/dam/amd/en/documents/instinct-tech-docs/instruction-set-architectures/amd-instinct-mi300-cdna3-instruction-set-architecture.pdf
            title: AMD Instinct MI300/CDNA3 ISA
          - url: https://www.amd.com/content/dam/amd/en/documents/instinct-tech-docs/white-papers/amd-cdna-3-white-paper.pdf
            title: White paper
          - file: conceptual/gpu-arch/mi300-mi200-performance-counters.rst
            title: MI300 and MI200 Performance counter
      - file: conceptual/gpu-arch/mi250.md
        title: MI250 microarchitecture
        subtrees:
        - entries:
          - url: https://www.amd.com/system/files/TechDocs/instinct-mi200-cdna2-instruction-set-architecture.pdf
            title: AMD Instinct MI200/CDNA2 ISA
          - url: https://www.amd.com/system/files/documents/amd-cdna2-white-paper.pdf
            title: White paper
      - file: conceptual/gpu-arch/mi100.md
        title: MI100 microarchitecture
        subtrees:
        - entries:
          - url: https://www.amd.com/system/files/TechDocs/instinct-mi100-cdna1-shader-instruction-set-architecture%C2%A0.pdf
            title: AMD Instinct MI100/CDNA1 ISA
          - url: https://www.amd.com/system/files/documents/amd-cdna-whitepaper.pdf
            title: White paper
  - file: conceptual/iommu.rst
    title: Input-Output Memory Management Unit (IOMMU)
  - file: conceptual/file-reorg.md
    title: File structure (Linux FHS)
  - file: conceptual/gpu-isolation.md
    title: GPU isolation techniques
  - file: conceptual/cmake-packages.rst
    title: Using CMake
  - file: conceptual/pcie-atomics.rst
    title: PCIe atomics in ROCm
  - file: conceptual/ai-pytorch-inception.md
    title: Inception v3 with PyTorch
  - file: conceptual/oversubscription.rst
    title: Oversubscription of hardware resources

- caption: Reference
  entries:
    - file: reference/api-libraries.md
      title: ROCm libraries
    - file: reference/rocm-tools.md
      title: ROCm tools, compilers, and runtimes
    - file: reference/gpu-arch-specs.rst
      title: Hardware specifications
    - file: reference/precision-support.rst
      title: Precision support
    - file: reference/graph-safe-support.rst
      title: Graph safe support

- caption: Contribute
  entries:
  - file: contribute/contributing.md
    title: Contributing to the ROCm docmentation
    subtrees:
    - entries:
      - file: contribute/toolchain.md
        title: ROCm documentation toolchain
      - file: contribute/building.md
  - file: contribute/feedback.md
    title: Providing feedback about the ROCm documentation
  - file: about/license.md
    title: ROCm licenses
